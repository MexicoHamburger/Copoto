{
  "best_global_step": 47286,
  "best_metric": 0.34514865279197693,
  "best_model_checkpoint": "./kcelectra_combined_hate_speech_lora/checkpoint-47286",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 47286,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021147908471852134,
      "grad_norm": 1.5356295108795166,
      "learning_rate": 1.9859295915633943e-05,
      "loss": 0.6262,
      "step": 500
    },
    {
      "epoch": 0.04229581694370427,
      "grad_norm": 1.6998625993728638,
      "learning_rate": 1.9718309859154933e-05,
      "loss": 0.4875,
      "step": 1000
    },
    {
      "epoch": 0.0634437254155564,
      "grad_norm": 2.2032854557037354,
      "learning_rate": 1.9577323802675915e-05,
      "loss": 0.4165,
      "step": 1500
    },
    {
      "epoch": 0.08459163388740853,
      "grad_norm": 6.067046165466309,
      "learning_rate": 1.9436337746196904e-05,
      "loss": 0.4051,
      "step": 2000
    },
    {
      "epoch": 0.10573954235926067,
      "grad_norm": 3.0957765579223633,
      "learning_rate": 1.929535168971789e-05,
      "loss": 0.3927,
      "step": 2500
    },
    {
      "epoch": 0.1268874508311128,
      "grad_norm": 2.0420312881469727,
      "learning_rate": 1.9154365633238875e-05,
      "loss": 0.3988,
      "step": 3000
    },
    {
      "epoch": 0.14803535930296494,
      "grad_norm": 1.6712923049926758,
      "learning_rate": 1.901337957675986e-05,
      "loss": 0.3918,
      "step": 3500
    },
    {
      "epoch": 0.16918326777481707,
      "grad_norm": 2.595897912979126,
      "learning_rate": 1.8872393520280847e-05,
      "loss": 0.3832,
      "step": 4000
    },
    {
      "epoch": 0.1903311762466692,
      "grad_norm": 3.2147421836853027,
      "learning_rate": 1.8731407463801832e-05,
      "loss": 0.3775,
      "step": 4500
    },
    {
      "epoch": 0.21147908471852134,
      "grad_norm": 4.223299980163574,
      "learning_rate": 1.8590421407322815e-05,
      "loss": 0.3935,
      "step": 5000
    },
    {
      "epoch": 0.23262699319037347,
      "grad_norm": 2.537612199783325,
      "learning_rate": 1.8449435350843804e-05,
      "loss": 0.3784,
      "step": 5500
    },
    {
      "epoch": 0.2537749016622256,
      "grad_norm": 4.216114044189453,
      "learning_rate": 1.830844929436479e-05,
      "loss": 0.3628,
      "step": 6000
    },
    {
      "epoch": 0.27492281013407777,
      "grad_norm": 3.225149154663086,
      "learning_rate": 1.8167463237885775e-05,
      "loss": 0.3674,
      "step": 6500
    },
    {
      "epoch": 0.2960707186059299,
      "grad_norm": 3.280853509902954,
      "learning_rate": 1.802647718140676e-05,
      "loss": 0.3806,
      "step": 7000
    },
    {
      "epoch": 0.31721862707778203,
      "grad_norm": 2.05039644241333,
      "learning_rate": 1.7885491124927746e-05,
      "loss": 0.3709,
      "step": 7500
    },
    {
      "epoch": 0.33836653554963414,
      "grad_norm": 3.4430527687072754,
      "learning_rate": 1.7744505068448732e-05,
      "loss": 0.3721,
      "step": 8000
    },
    {
      "epoch": 0.3595144440214863,
      "grad_norm": 2.5388708114624023,
      "learning_rate": 1.7603519011969718e-05,
      "loss": 0.3641,
      "step": 8500
    },
    {
      "epoch": 0.3806623524933384,
      "grad_norm": 2.362725019454956,
      "learning_rate": 1.7462532955490703e-05,
      "loss": 0.3685,
      "step": 9000
    },
    {
      "epoch": 0.40181026096519057,
      "grad_norm": 1.9854092597961426,
      "learning_rate": 1.732154689901169e-05,
      "loss": 0.3629,
      "step": 9500
    },
    {
      "epoch": 0.4229581694370427,
      "grad_norm": 3.076672315597534,
      "learning_rate": 1.7180560842532675e-05,
      "loss": 0.3535,
      "step": 10000
    },
    {
      "epoch": 0.44410607790889484,
      "grad_norm": 2.375584125518799,
      "learning_rate": 1.703957478605366e-05,
      "loss": 0.3507,
      "step": 10500
    },
    {
      "epoch": 0.46525398638074694,
      "grad_norm": 3.2985193729400635,
      "learning_rate": 1.6898588729574646e-05,
      "loss": 0.3587,
      "step": 11000
    },
    {
      "epoch": 0.4864018948525991,
      "grad_norm": 14.179441452026367,
      "learning_rate": 1.6757602673095632e-05,
      "loss": 0.3559,
      "step": 11500
    },
    {
      "epoch": 0.5075498033244512,
      "grad_norm": 3.1327409744262695,
      "learning_rate": 1.6616616616616618e-05,
      "loss": 0.3791,
      "step": 12000
    },
    {
      "epoch": 0.5286977117963033,
      "grad_norm": 2.221705675125122,
      "learning_rate": 1.6475630560137603e-05,
      "loss": 0.3521,
      "step": 12500
    },
    {
      "epoch": 0.5498456202681555,
      "grad_norm": 2.5586040019989014,
      "learning_rate": 1.633464450365859e-05,
      "loss": 0.3609,
      "step": 13000
    },
    {
      "epoch": 0.5709935287400076,
      "grad_norm": 1.545999526977539,
      "learning_rate": 1.6193658447179575e-05,
      "loss": 0.3509,
      "step": 13500
    },
    {
      "epoch": 0.5921414372118597,
      "grad_norm": 4.784600734710693,
      "learning_rate": 1.605267239070056e-05,
      "loss": 0.3522,
      "step": 14000
    },
    {
      "epoch": 0.6132893456837119,
      "grad_norm": 2.4965572357177734,
      "learning_rate": 1.591168633422155e-05,
      "loss": 0.3525,
      "step": 14500
    },
    {
      "epoch": 0.6344372541555641,
      "grad_norm": 2.896984577178955,
      "learning_rate": 1.577070027774253e-05,
      "loss": 0.3578,
      "step": 15000
    },
    {
      "epoch": 0.6555851626274162,
      "grad_norm": 3.2749335765838623,
      "learning_rate": 1.5629714221263517e-05,
      "loss": 0.359,
      "step": 15500
    },
    {
      "epoch": 0.6767330710992683,
      "grad_norm": 2.4982948303222656,
      "learning_rate": 1.5488728164784503e-05,
      "loss": 0.3614,
      "step": 16000
    },
    {
      "epoch": 0.6978809795711204,
      "grad_norm": 1.7029633522033691,
      "learning_rate": 1.534774210830549e-05,
      "loss": 0.3637,
      "step": 16500
    },
    {
      "epoch": 0.7190288880429726,
      "grad_norm": 1.039139747619629,
      "learning_rate": 1.5206756051826474e-05,
      "loss": 0.3481,
      "step": 17000
    },
    {
      "epoch": 0.7401767965148247,
      "grad_norm": 3.3578054904937744,
      "learning_rate": 1.5065769995347462e-05,
      "loss": 0.3583,
      "step": 17500
    },
    {
      "epoch": 0.7613247049866768,
      "grad_norm": 3.022155523300171,
      "learning_rate": 1.4924783938868447e-05,
      "loss": 0.358,
      "step": 18000
    },
    {
      "epoch": 0.7824726134585289,
      "grad_norm": 2.39398193359375,
      "learning_rate": 1.4783797882389433e-05,
      "loss": 0.3469,
      "step": 18500
    },
    {
      "epoch": 0.8036205219303811,
      "grad_norm": 2.1063950061798096,
      "learning_rate": 1.4642811825910419e-05,
      "loss": 0.3749,
      "step": 19000
    },
    {
      "epoch": 0.8247684304022332,
      "grad_norm": 2.5426383018493652,
      "learning_rate": 1.4501825769431403e-05,
      "loss": 0.3581,
      "step": 19500
    },
    {
      "epoch": 0.8459163388740853,
      "grad_norm": 2.052943706512451,
      "learning_rate": 1.436083971295239e-05,
      "loss": 0.3632,
      "step": 20000
    },
    {
      "epoch": 0.8670642473459375,
      "grad_norm": 2.9479386806488037,
      "learning_rate": 1.4219853656473378e-05,
      "loss": 0.3444,
      "step": 20500
    },
    {
      "epoch": 0.8882121558177897,
      "grad_norm": 3.3860883712768555,
      "learning_rate": 1.4078867599994362e-05,
      "loss": 0.3599,
      "step": 21000
    },
    {
      "epoch": 0.9093600642896418,
      "grad_norm": 1.9791229963302612,
      "learning_rate": 1.3937881543515349e-05,
      "loss": 0.3591,
      "step": 21500
    },
    {
      "epoch": 0.9305079727614939,
      "grad_norm": 4.9732537269592285,
      "learning_rate": 1.3796895487036333e-05,
      "loss": 0.3523,
      "step": 22000
    },
    {
      "epoch": 0.951655881233346,
      "grad_norm": 3.329800605773926,
      "learning_rate": 1.3655909430557319e-05,
      "loss": 0.3423,
      "step": 22500
    },
    {
      "epoch": 0.9728037897051982,
      "grad_norm": 3.4267637729644775,
      "learning_rate": 1.3514923374078304e-05,
      "loss": 0.3494,
      "step": 23000
    },
    {
      "epoch": 0.9939516981770503,
      "grad_norm": 3.2090256214141846,
      "learning_rate": 1.337393731759929e-05,
      "loss": 0.3571,
      "step": 23500
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.8645548880393228,
      "eval_loss": 0.3483840823173523,
      "eval_runtime": 95.0055,
      "eval_samples_per_second": 497.708,
      "eval_steps_per_second": 31.114,
      "step": 23643
    },
    {
      "epoch": 1.0150996066489024,
      "grad_norm": 2.4147260189056396,
      "learning_rate": 1.3232951261120277e-05,
      "loss": 0.3518,
      "step": 24000
    },
    {
      "epoch": 1.0362475151207546,
      "grad_norm": 1.2018927335739136,
      "learning_rate": 1.3091965204641261e-05,
      "loss": 0.3571,
      "step": 24500
    },
    {
      "epoch": 1.0573954235926066,
      "grad_norm": 2.0718536376953125,
      "learning_rate": 1.2950979148162249e-05,
      "loss": 0.3488,
      "step": 25000
    },
    {
      "epoch": 1.0785433320644588,
      "grad_norm": 3.868445634841919,
      "learning_rate": 1.2809993091683233e-05,
      "loss": 0.3545,
      "step": 25500
    },
    {
      "epoch": 1.0996912405363108,
      "grad_norm": 0.6965459585189819,
      "learning_rate": 1.266900703520422e-05,
      "loss": 0.3441,
      "step": 26000
    },
    {
      "epoch": 1.120839149008163,
      "grad_norm": 3.8034403324127197,
      "learning_rate": 1.2528020978725206e-05,
      "loss": 0.3547,
      "step": 26500
    },
    {
      "epoch": 1.1419870574800153,
      "grad_norm": 1.8204972743988037,
      "learning_rate": 1.238703492224619e-05,
      "loss": 0.3411,
      "step": 27000
    },
    {
      "epoch": 1.1631349659518673,
      "grad_norm": 2.764486074447632,
      "learning_rate": 1.2246048865767177e-05,
      "loss": 0.3465,
      "step": 27500
    },
    {
      "epoch": 1.1842828744237195,
      "grad_norm": 2.4358553886413574,
      "learning_rate": 1.2105062809288161e-05,
      "loss": 0.3486,
      "step": 28000
    },
    {
      "epoch": 1.2054307828955717,
      "grad_norm": 5.146897792816162,
      "learning_rate": 1.1964076752809148e-05,
      "loss": 0.344,
      "step": 28500
    },
    {
      "epoch": 1.2265786913674237,
      "grad_norm": 7.170365810394287,
      "learning_rate": 1.1823090696330132e-05,
      "loss": 0.3348,
      "step": 29000
    },
    {
      "epoch": 1.247726599839276,
      "grad_norm": 3.2964420318603516,
      "learning_rate": 1.168210463985112e-05,
      "loss": 0.3376,
      "step": 29500
    },
    {
      "epoch": 1.2688745083111281,
      "grad_norm": 1.7219207286834717,
      "learning_rate": 1.1541118583372105e-05,
      "loss": 0.3435,
      "step": 30000
    },
    {
      "epoch": 1.2900224167829801,
      "grad_norm": 1.7920124530792236,
      "learning_rate": 1.1400132526893091e-05,
      "loss": 0.349,
      "step": 30500
    },
    {
      "epoch": 1.3111703252548323,
      "grad_norm": 3.4561409950256348,
      "learning_rate": 1.1259146470414077e-05,
      "loss": 0.3462,
      "step": 31000
    },
    {
      "epoch": 1.3323182337266846,
      "grad_norm": 4.370491027832031,
      "learning_rate": 1.1118160413935063e-05,
      "loss": 0.3574,
      "step": 31500
    },
    {
      "epoch": 1.3534661421985366,
      "grad_norm": 2.572422742843628,
      "learning_rate": 1.0977174357456048e-05,
      "loss": 0.3569,
      "step": 32000
    },
    {
      "epoch": 1.3746140506703888,
      "grad_norm": 4.404078960418701,
      "learning_rate": 1.0836188300977036e-05,
      "loss": 0.3413,
      "step": 32500
    },
    {
      "epoch": 1.3957619591422408,
      "grad_norm": 3.7632083892822266,
      "learning_rate": 1.069520224449802e-05,
      "loss": 0.3508,
      "step": 33000
    },
    {
      "epoch": 1.416909867614093,
      "grad_norm": 2.9039714336395264,
      "learning_rate": 1.0554216188019007e-05,
      "loss": 0.3466,
      "step": 33500
    },
    {
      "epoch": 1.438057776085945,
      "grad_norm": 4.152955055236816,
      "learning_rate": 1.0413230131539991e-05,
      "loss": 0.3428,
      "step": 34000
    },
    {
      "epoch": 1.4592056845577972,
      "grad_norm": 2.421407699584961,
      "learning_rate": 1.0272244075060978e-05,
      "loss": 0.3459,
      "step": 34500
    },
    {
      "epoch": 1.4803535930296494,
      "grad_norm": 2.014456272125244,
      "learning_rate": 1.0131258018581962e-05,
      "loss": 0.3489,
      "step": 35000
    },
    {
      "epoch": 1.5015015015015014,
      "grad_norm": 4.556264400482178,
      "learning_rate": 9.990271962102948e-06,
      "loss": 0.3507,
      "step": 35500
    },
    {
      "epoch": 1.5226494099733536,
      "grad_norm": 1.9618936777114868,
      "learning_rate": 9.849285905623934e-06,
      "loss": 0.3347,
      "step": 36000
    },
    {
      "epoch": 1.5437973184452058,
      "grad_norm": 2.4402918815612793,
      "learning_rate": 9.70829984914492e-06,
      "loss": 0.3444,
      "step": 36500
    },
    {
      "epoch": 1.5649452269170578,
      "grad_norm": 4.439415454864502,
      "learning_rate": 9.567313792665907e-06,
      "loss": 0.3452,
      "step": 37000
    },
    {
      "epoch": 1.58609313538891,
      "grad_norm": 3.0350422859191895,
      "learning_rate": 9.426327736186892e-06,
      "loss": 0.343,
      "step": 37500
    },
    {
      "epoch": 1.6072410438607623,
      "grad_norm": 5.192998886108398,
      "learning_rate": 9.285341679707878e-06,
      "loss": 0.3495,
      "step": 38000
    },
    {
      "epoch": 1.6283889523326143,
      "grad_norm": 3.4108614921569824,
      "learning_rate": 9.144355623228864e-06,
      "loss": 0.3353,
      "step": 38500
    },
    {
      "epoch": 1.6495368608044665,
      "grad_norm": 1.7296957969665527,
      "learning_rate": 9.00336956674985e-06,
      "loss": 0.336,
      "step": 39000
    },
    {
      "epoch": 1.6706847692763187,
      "grad_norm": 3.199413537979126,
      "learning_rate": 8.862383510270835e-06,
      "loss": 0.3404,
      "step": 39500
    },
    {
      "epoch": 1.6918326777481707,
      "grad_norm": 3.6242117881774902,
      "learning_rate": 8.72139745379182e-06,
      "loss": 0.3503,
      "step": 40000
    },
    {
      "epoch": 1.7129805862200227,
      "grad_norm": 3.4924354553222656,
      "learning_rate": 8.580411397312807e-06,
      "loss": 0.3279,
      "step": 40500
    },
    {
      "epoch": 1.7341284946918751,
      "grad_norm": 3.8714590072631836,
      "learning_rate": 8.439425340833792e-06,
      "loss": 0.3537,
      "step": 41000
    },
    {
      "epoch": 1.7552764031637271,
      "grad_norm": 2.895892381668091,
      "learning_rate": 8.298439284354778e-06,
      "loss": 0.3425,
      "step": 41500
    },
    {
      "epoch": 1.7764243116355791,
      "grad_norm": 2.585906982421875,
      "learning_rate": 8.157453227875764e-06,
      "loss": 0.3506,
      "step": 42000
    },
    {
      "epoch": 1.7975722201074313,
      "grad_norm": 3.5350210666656494,
      "learning_rate": 8.01646717139675e-06,
      "loss": 0.3491,
      "step": 42500
    },
    {
      "epoch": 1.8187201285792836,
      "grad_norm": 2.9514262676239014,
      "learning_rate": 7.875481114917735e-06,
      "loss": 0.3442,
      "step": 43000
    },
    {
      "epoch": 1.8398680370511356,
      "grad_norm": 2.1787447929382324,
      "learning_rate": 7.73449505843872e-06,
      "loss": 0.3448,
      "step": 43500
    },
    {
      "epoch": 1.8610159455229878,
      "grad_norm": 2.5739517211914062,
      "learning_rate": 7.593509001959707e-06,
      "loss": 0.3528,
      "step": 44000
    },
    {
      "epoch": 1.88216385399484,
      "grad_norm": 1.5072335004806519,
      "learning_rate": 7.452522945480693e-06,
      "loss": 0.3425,
      "step": 44500
    },
    {
      "epoch": 1.903311762466692,
      "grad_norm": 3.552885055541992,
      "learning_rate": 7.311536889001678e-06,
      "loss": 0.3321,
      "step": 45000
    },
    {
      "epoch": 1.9244596709385442,
      "grad_norm": 2.7979934215545654,
      "learning_rate": 7.170550832522663e-06,
      "loss": 0.347,
      "step": 45500
    },
    {
      "epoch": 1.9456075794103964,
      "grad_norm": 2.2513837814331055,
      "learning_rate": 7.029564776043651e-06,
      "loss": 0.342,
      "step": 46000
    },
    {
      "epoch": 1.9667554878822484,
      "grad_norm": 7.019099712371826,
      "learning_rate": 6.8885787195646355e-06,
      "loss": 0.3523,
      "step": 46500
    },
    {
      "epoch": 1.9879033963541006,
      "grad_norm": 2.4904425144195557,
      "learning_rate": 6.747592663085621e-06,
      "loss": 0.3378,
      "step": 47000
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.8671242384514537,
      "eval_loss": 0.34514865279197693,
      "eval_runtime": 97.6922,
      "eval_samples_per_second": 484.02,
      "eval_steps_per_second": 30.258,
      "step": 47286
    }
  ],
  "logging_steps": 500,
  "max_steps": 70929,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.202621883448221e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
